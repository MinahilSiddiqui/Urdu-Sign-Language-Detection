{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8def3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# Path to the dataset\n",
    "dataset_path = r\"C:\\Users\\PMLS\\Documents\\2ndSemester\\CV\\cvProject\\PSL\\UAlpha\"\n",
    "\n",
    "# Mapping English folder names to Urdu labels\n",
    "english_to_urdu = {\n",
    "    \"Alif\": \"ا\",\n",
    "    \"Bay\": \"ب\",\n",
    "    \"Pay\": \"پ\",\n",
    "    \"Tay\": \"ت\",\n",
    "    \"Taay\": \"ٹ\",\n",
    "    \"Say\": \"ث\",\n",
    "    \"Chay\": \"چ\",\n",
    "    \"1-Hay\": \"ح\",\n",
    "    \"Khay\": \"خ\",\n",
    "    \"Dal\": \"د\",\n",
    "    \"Daal\": \"ڈ\",\n",
    "    \"Zaal\": \"ذ\",\n",
    "    \"Ray\": \"ر\",\n",
    "    \"Zay\": \"ز\",\n",
    "    \"Zaey\": \"ژ\",\n",
    "    \"Seen\": \"س\",\n",
    "    \"Sheen\": \"ش\",\n",
    "    \"Suad\": \"ص\",\n",
    "    \"Zuad\": \"ض\",\n",
    "    \"Tuey\": \"ط\",\n",
    "    \"Zuey\": \"ظ\",\n",
    "    \"Ain\": \"ع\",\n",
    "    \"Ghain\": \"غ\",\n",
    "    \"Fay\": \"ف\",\n",
    "    \"Kaf\": \"ق\",\n",
    "    \"Kiaf\": \"ک\",\n",
    "    \"Gaaf\": \"گ\",\n",
    "    \"Lam\": \"ل\",\n",
    "    \"Meem\": \"م\",\n",
    "    \"Nuun\": \"ن\",\n",
    "    \"Nuungh\": \"ں\",\n",
    "    \"Wao\": \"و\",\n",
    "    \"Dochahay\": \"ھ\",\n",
    "    \"Hamza\": \"ء\",\n",
    "    \"Cyeh\": \"ى\",\n",
    "    \"Byeh\": \"ے\"\n",
    "}\n",
    "\n",
    "# Output CSV files\n",
    "train_csv = \"train_dataset.csv\"\n",
    "test_csv = \"test_dataset.csv\"\n",
    "\n",
    "# Train-test split ratio\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Prepare CSV data\n",
    "data = []\n",
    "\n",
    "for folder_name in os.listdir(dataset_path):\n",
    "    folder_path = os.path.join(dataset_path, folder_name)\n",
    "    if os.path.isdir(folder_path) and folder_name in english_to_urdu:\n",
    "        urdu_label = english_to_urdu[folder_name]\n",
    "        for image_name in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            data.append([image_path, urdu_label])\n",
    "\n",
    "# Shuffle the data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split the data\n",
    "train_size = int(len(data) * train_ratio)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "# Write to train CSV\n",
    "with open(train_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"image_path\", \"label\"])  # Header\n",
    "    writer.writerows(train_data)\n",
    "\n",
    "# Write to test CSV\n",
    "with open(test_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"image_path\", \"label\"])  # Header\n",
    "    writer.writerows(test_data)\n",
    "\n",
    "print(f\"Train CSV file created: {train_csv}\")\n",
    "print(f\"Test CSV file created: {test_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# Paths to CSV files and dataset folder\n",
    "train_csv = \"train_dataset.csv\"\n",
    "test_csv = \"test_dataset.csv\"\n",
    "dataset_path = r\"C:\\Users\\PMLS\\Documents\\2ndSemester\\CV\\cvProject\\PSL\\UAlpha\"\n",
    "\n",
    "# Image processing parameters\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, label):\n",
    "    # Load and preprocess the image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = tf.keras.applications.mobilenet_v3.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Function to load and preprocess data from CSV\n",
    "def load_dataset(csv_file, label_encoder):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Ensure the image_path column contains valid paths (no need to prepend dataset_path)\n",
    "    \n",
    "    # Encode labels\n",
    "    df['label'] = label_encoder.transform(df['label'])\n",
    "    \n",
    "    # Create a TensorFlow dataset\n",
    "    image_paths = df['image_path'].values\n",
    "    labels = df['label'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(preprocess_image)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load the training and test datasets\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode labels using all data (train + test for consistency)\n",
    "all_labels = pd.concat([pd.read_csv(train_csv)['label'], pd.read_csv(test_csv)['label']])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "train_dataset = load_dataset(train_csv, label_encoder)\n",
    "test_dataset = load_dataset(test_csv, label_encoder)\n",
    "\n",
    "# Define MobileNetV3 model\n",
    "def create_mobilenet_v3_model(num_classes):\n",
    "    base_model = tf.keras.applications.MobileNetV3Large(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = create_mobilenet_v3_model(num_classes)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=epochs)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"mobilenet_v3_urdu_alphabets.h5\")\n",
    "keras.saving.save_model(model, 'my_model.keras')\n",
    "\n",
    "# Evaluate the model\n",
    "test_images, test_labels = [], []\n",
    "for img, lbl in test_dataset.unbatch():\n",
    "    test_images.append(img.numpy())\n",
    "    test_labels.append(lbl.numpy())\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(test_labels, y_pred, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "\n",
    "# Paths to CSV files\n",
    "train_csv = \"train_dataset.csv\"\n",
    "test_csv = \"test_dataset.csv\"\n",
    "\n",
    "# Image processing parameters\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# Preprocess image function\n",
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = tf.keras.applications.efficientnet_v2.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset(csv_file, label_encoder):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['label'] = label_encoder.transform(df['label'])\n",
    "    image_paths = df['image_path'].values\n",
    "    labels = df['label'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Prepare datasets\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels = pd.concat([pd.read_csv(train_csv)['label'], pd.read_csv(test_csv)['label']])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "train_dataset = load_dataset(train_csv, label_encoder)\n",
    "test_dataset = load_dataset(test_csv, label_encoder)\n",
    "\n",
    "# Create model\n",
    "def create_efficientnet_model(num_classes):\n",
    "    base_model = tf.keras.applications.EfficientNetB0(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax', dtype=\"float32\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Model creation and training\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = create_efficientnet_model(num_classes)\n",
    "model.fit(train_dataset, epochs=epochs)\n",
    "\n",
    "# Fine-tuning\n",
    "base_model = model.get_layer(index=0)\n",
    "base_model.trainable = True\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(train_dataset, epochs=5)\n",
    "\n",
    "# Save model\n",
    "model.save(\"efficientnet_urdu_alphabets.keras\")\n",
    "model.save(\"efficientb0_urdu_alphabets.h5\")\n",
    "# Evaluation\n",
    "results = model.evaluate(test_dataset, batch_size=batch_size)\n",
    "print(f\"Test Accuracy: {results[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"efficientnet_urdu_alphabets.keras\", compile=False)\n",
    "\n",
    "# Define label names for predictions\n",
    "labels = [\n",
    "    \"ء\", \"ا\", \"ب\", \"ت\", \"ث\", \"ح\", \"خ\", \"د\", \"ذ\", \"ر\", \"ز\", \"س\", \"ش\", \"ص\", \"ض\",\n",
    "    \"ط\", \"ظ\", \"ع\", \"غ\", \"ف\", \"ق\", \"ل\", \"م\", \"ن\", \"و\", \"ى\", \"ٹ\", \"پ\", \"چ\", \"ڈ\",\n",
    "    \"ژ\", \"ک\", \"گ\", \"ں\", \"ھ\", \"ے\"\n",
    "]\n",
    "\n",
    "# Camera settings\n",
    "camera = cv2.VideoCapture(0)\n",
    "box_size = 224  # Square box dimensions for capturing hand region\n",
    "x1, y1 = 100, 100  # Top-left corner of the box\n",
    "\n",
    "print(\"Press 'c' to capture an image for prediction.\")\n",
    "print(\"Press 'q' to quit the application.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Flip the frame for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Draw a bounding box on the frame\n",
    "    x2, y2 = x1 + box_size, y1 + box_size\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Display instructions on the screen\n",
    "    cv2.putText(frame, \"Press 'c' to capture, 'q' to quit\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Sign Language Detection\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('c'):  # Capture image for prediction\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "        # Preprocess the ROI for prediction\n",
    "        img = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = tf.keras.applications.efficientnet.preprocess_input(img.astype(np.float32))\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        # Predict the sign\n",
    "        predictions = model.predict(img)\n",
    "        predicted_label = labels[np.argmax(predictions)]\n",
    "\n",
    "        # Display the prediction on the frame\n",
    "        cv2.putText(frame, f\"Predicted: {predicted_label}\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the prediction\n",
    "        print(f\"Predicted: {predicted_label}\")\n",
    "\n",
    "    elif key == ord('q'):  # Quit the application\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842abd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to CSV files and dataset folder\n",
    "train_csv = \"train_dataset.csv\"\n",
    "test_csv = \"test_dataset.csv\"\n",
    "dataset_path = r\"C:\\Users\\PMLS\\Documents\\2ndSemester\\CV\\cvProject\\PSL\\UAlpha\"\n",
    "\n",
    "# Image processing parameters\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = tf.keras.applications.mobilenet_v3.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Function to load and preprocess data from CSV\n",
    "def load_dataset(csv_file, label_encoder):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['label'] = label_encoder.transform(df['label'])\n",
    "    image_paths = df['image_path'].values\n",
    "    labels = df['label'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(preprocess_image)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load the training and test datasets\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels = pd.concat([pd.read_csv(train_csv)['label'], pd.read_csv(test_csv)['label']])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "train_dataset = load_dataset(train_csv, label_encoder)\n",
    "test_dataset = load_dataset(test_csv, label_encoder)\n",
    "\n",
    "# Define MobileNetV3 model\n",
    "def create_mobilenet_v3_model(num_classes):\n",
    "    base_model = tf.keras.applications.MobileNetV3Large(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = create_mobilenet_v3_model(num_classes)\n",
    "\n",
    "model.fit(train_dataset, epochs=epochs)\n",
    "\n",
    "# Save the model in Keras format\n",
    "model.save(\"mobilenet_v3_urdu_alphabets.h5\")\n",
    "#tf.keras.saving.save_model(model, 'mobilenet_v3_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0723443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model in Pickle format\n",
    "import pickle\n",
    "with open(\"mobilenet_v3_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Evaluate the model\n",
    "test_images, test_labels = [], []\n",
    "for img, lbl in test_dataset.unbatch():\n",
    "    test_images.append(img.numpy())\n",
    "    test_labels.append(lbl.numpy())\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate and save the classification report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(test_labels, y_pred, target_names=class_names, output_dict=True)\n",
    "with open(\"CLASSFICATIONreportmbilenetv3.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=4)\n",
    "print(\"Classification Report saved to CLASSFICATIONreportmbilenetv3.json\")\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "# Save confusion matrix as an image\n",
    "plt.savefig(\"confusion_matrix_mobilenet_v3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c99a5fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at saved_mobilenetv3_model.keras\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Define the file path to save the model\n",
    "keras_model_save_path = 'saved_mobilenetv3_model.keras'\n",
    "\n",
    "# Save the model in Keras format (.h5)\n",
    "model.save(keras_model_save_path)\n",
    "print(f\"Model saved at {keras_model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a473a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to CSV files and dataset folder\n",
    "train_csv = \"train_dataset.csv\"\n",
    "test_csv = \"test_dataset.csv\"\n",
    "dataset_path = r\"C:\\Users\\PMLS\\Documents\\2ndSemester\\CV\\cvProject\\PSL\\UAlpha\"\n",
    "\n",
    "# Image processing parameters\n",
    "image_size = (224, 224)\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Function to load and preprocess data from CSV\n",
    "def load_dataset(csv_file, label_encoder):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['label'] = label_encoder.transform(df['label'])\n",
    "    image_paths = df['image_path'].values\n",
    "    labels = df['label'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(preprocess_image)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load the training and test datasets\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels = pd.concat([pd.read_csv(train_csv)['label'], pd.read_csv(test_csv)['label']])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "train_dataset = load_dataset(train_csv, label_encoder)\n",
    "test_dataset = load_dataset(test_csv, label_encoder)\n",
    "\n",
    "# Define MobileNetV2 model\n",
    "def create_mobilenet_v2_model(num_classes):\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = create_mobilenet_v2_model(num_classes)\n",
    "\n",
    "model.fit(train_dataset, epochs=epochs)\n",
    "\n",
    "# Save the model in Keras format\n",
    "model.save(\"mobilenet_v2_urdu_alphabets.h5\")\n",
    "print(\"Model saved in Keras format as mobilenet_v2_urdu_alphabets.h5\")\n",
    "\n",
    "# Save the model in Pickle format\n",
    "import pickle\n",
    "with open(\"mobilenet_v2_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"Model saved in Pickle format as mobilenet_v2_model.pkl\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_images, test_labels = [], []\n",
    "for img, lbl in test_dataset.unbatch():\n",
    "    test_images.append(img.numpy())\n",
    "    test_labels.append(lbl.numpy())\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate and save the classification report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(test_labels, y_pred, target_names=class_names, output_dict=True)\n",
    "with open(\"CLASSFICATIONreportmobilenetv2.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=4)\n",
    "print(\"Classification Report saved to CLASSFICATIONreportmobilenetv2.json\")\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Save confusion matrix as an image\n",
    "plt.savefig(\"confusion_matrix_mobilenet_v2.png\")\n",
    "print(\"Confusion Matrix saved as confusion_matrix_mobilenet_v2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model in Keras format\n",
    "model.save(\"mobilenet_v2_urdu_alphabets.h5\")\n",
    "print(\"Model saved in Keras format as mobilenet_v2_urdu_alphabets.h5\")\n",
    "\n",
    "# Save the model in Pickle format\n",
    "import pickle\n",
    "with open(\"mobilenet_v2_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"Model saved in Pickle format as mobilenet_v2_model.pkl\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_images, test_labels = [], []\n",
    "for img, lbl in test_dataset.unbatch():\n",
    "    test_images.append(img.numpy())\n",
    "    test_labels.append(lbl.numpy())\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate and save the classification report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(test_labels, y_pred, target_names=class_names, output_dict=True)\n",
    "# Generate classification report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(test_labels, y_pred, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "with open(\"CLASSFICATIONreportmobilenetv2.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=4)\n",
    "print(\"Classification Report saved to CLASSFICATIONreportmobilenetv2.json\")\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Save confusion matrix as an image\n",
    "plt.savefig(\"confusion_matrix_mobilenet_v2.png\")\n",
    "print(\"Confusion Matrix saved as confusion_matrix_mobilenet_v2.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8240d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(test_labels, y_pred, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to CSV files and dataset folder\n",
    "train_csv = \"train_dataset.csv\"\n",
    "test_csv = \"test_dataset.csv\"\n",
    "dataset_path = r\"C:\\Users\\PMLS\\Documents\\2ndSemester\\CV\\cvProject\\PSL\\UAlpha\"\n",
    "\n",
    "# Image processing parameters\n",
    "image_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Function to load and preprocess data from CSV\n",
    "def load_dataset(csv_file, label_encoder):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['label'] = label_encoder.transform(df['label'])\n",
    "    image_paths = df['image_path'].values\n",
    "    labels = df['label'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    dataset = dataset.map(preprocess_image)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load the training and test datasets\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels = pd.concat([pd.read_csv(train_csv)['label'], pd.read_csv(test_csv)['label']])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "train_dataset = load_dataset(train_csv, label_encoder)\n",
    "test_dataset = load_dataset(test_csv, label_encoder)\n",
    "\n",
    "# Define EfficientNet model\n",
    "def create_efficientnet_model(num_classes):\n",
    "    base_model = tf.keras.applications.EfficientNetB0(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False  # Freeze base model weights\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = create_efficientnet_model(num_classes)\n",
    "\n",
    "# Training with ModelCheckpoint to save the best model\n",
    "checkpoint_path = \"efficientnet_model_best.h5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# Save the model in Keras format\n",
    "model.save(\"efficientnet_model.h5\")\n",
    "\n",
    "# Save the model in Pickle format\n",
    "import pickle\n",
    "with open(\"efficientnet_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Evaluate the model\n",
    "test_images, test_labels = [], []\n",
    "for img, lbl in test_dataset.unbatch():\n",
    "    test_images.append(img.numpy())\n",
    "    test_labels.append(lbl.numpy())\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate and save the classification report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(test_labels, y_pred, target_names=class_names, output_dict=True)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "with open(\"classification_report_efficientnet.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=4)\n",
    "print(\"Classification Report saved to classification_report_efficientnet.json\")\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig(\"confusion_matrix_efficientnet.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df8971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model in Keras format\n",
    "model.save(\"efficientnet_model.h5\")\n",
    "\n",
    "# Save the model in Pickle format\n",
    "import pickle\n",
    "with open(\"efficientnet_modelNEW.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Evaluate the model\n",
    "test_images, test_labels = [], []\n",
    "for img, lbl in test_dataset.unbatch():\n",
    "    test_images.append(img.numpy())\n",
    "    test_labels.append(lbl.numpy())\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Generate and save the classification report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(test_labels, y_pred, target_names=class_names, output_dict=True)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "with open(\"classification_report_efficientnet.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=4)\n",
    "print(\"Classification Report saved to classification_report_efficientnet.json\")\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig(\"confusion_matrix_efficientnet.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "# === Load Models ===\n",
    "# Load model saved as a .pkl file\n",
    "model_path = \"mobilenet_v2_model.pkl\"\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model2 = pickle.load(f)\n",
    "\n",
    "# Load other models\n",
    "model1 = tf.keras.models.load_model(\"efficientnet_urdu_alphabets.keras\", compile=False)\n",
    "model3 = tf.keras.models.load_model(\"saved_mobilenetv3_model.keras\", compile=False)\n",
    "\n",
    "# === Label Definitions ===\n",
    "labels = [\n",
    "    \"ء\", \"ا\", \"ب\", \"ت\", \"ث\", \"ح\", \"خ\", \"د\", \"ذ\", \"ر\", \"ز\", \"س\", \"ش\", \"ص\", \"ض\",\n",
    "    \"ط\", \"ظ\", \"ع\", \"غ\", \"ف\", \"ق\", \"ل\", \"م\", \"ن\", \"و\", \"ى\", \"ٹ\", \"پ\", \"چ\", \"ڈ\",\n",
    "    \"ژ\", \"ک\", \"گ\", \"ں\", \"ھ\", \"ے\"\n",
    "]\n",
    "\n",
    "# === Camera Settings ===\n",
    "camera = cv2.VideoCapture(0)\n",
    "if not camera.isOpened():\n",
    "    print(\"Error: Unable to access the camera.\")\n",
    "    exit()\n",
    "\n",
    "box_size = 224\n",
    "x1, y1 = 100, 100  # Top-left corner of the bounding box\n",
    "\n",
    "print(\"Press 'c' to capture an image for prediction.\")\n",
    "print(\"Press 'q' to quit the application.\")\n",
    "\n",
    "# === Main Loop ===\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read from the camera.\")\n",
    "        break\n",
    "\n",
    "    # Flip frame for a mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Define and draw bounding box\n",
    "    x2, y2 = x1 + box_size, y1 + box_size\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Display instructions\n",
    "    cv2.putText(frame, \"Press 'c' to capture, 'q' to quit\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "    # Show the live video feed\n",
    "    cv2.imshow(\"Sign Language Detection\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('c'):  # Capture image\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "        # Preprocess the ROI\n",
    "        img = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = tf.keras.applications.efficientnet.preprocess_input(img.astype(np.float32))\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        # Get predictions from all models\n",
    "        predictions1 = model1.predict(img)\n",
    "        predictions2 = model2.predict(img)\n",
    "        predictions3 = model3.predict(img)\n",
    "\n",
    "        # Get the predicted labels\n",
    "        pred_label1 = labels[np.argmax(predictions1)]\n",
    "        pred_label2 = labels[np.argmax(predictions2)]\n",
    "        pred_label3 = labels[np.argmax(predictions3)]\n",
    "\n",
    "        # Perform ensemble prediction using majority voting\n",
    "        final_prediction = Counter([pred_label1, pred_label2, pred_label3]).most_common(1)[0][0]\n",
    "\n",
    "        # Overlay predictions on the frame\n",
    "        cv2.putText(frame, f\"Model 1: {pred_label1}\", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Model 2: {pred_label2}\", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Model 3: {pred_label3}\", (10, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Final Prediction: {final_prediction}\", (10, 160), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display predictions in the console\n",
    "        print(f\"Model 1 Prediction: {pred_label1}\")\n",
    "        print(f\"Model 2 Prediction: {pred_label2}\")\n",
    "        print(f\"Model 3 Prediction: {pred_label3}\")\n",
    "        print(f\"Ensemble Prediction: {final_prediction}\")\n",
    "\n",
    "        # Display the updated frame\n",
    "        cv2.imshow(\"Sign Language Detection\", frame)\n",
    "\n",
    "    elif key == ord('q'):  # Quit\n",
    "        break\n",
    "\n",
    "# === Cleanup ===\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
